{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc6519a5",
   "metadata": {},
   "source": [
    "# See-Think-Act Agent Demo for Windows 11\n",
    "\n",
    "This notebook demonstrates the autonomous AI Agent that can see, think, and act to perform tasks on Windows 11 using Ollama with Qwen3-VL.\n",
    "\n",
    "## Features\n",
    "- **See**: Captures screenshots of the desktop using efficient Windows APIs\n",
    "- **Think**: Analyzes screenshots with Qwen3-VL model via Ollama\n",
    "- **Act**: Executes mouse, keyboard, and system actions autonomously\n",
    "- **Loop**: Continues until task completion or max iterations reached\n",
    "\n",
    "## Prerequisites\n",
    "1. Ollama installed and running\n",
    "2. Qwen3-VL model pulled: `ollama run qwen3-vl:235b-cloud`\n",
    "3. Required Python packages installed (see requirements.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b76c5a6",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea980f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install mss\n",
    "!pip install pyautogui\n",
    "!pip install ollama\n",
    "!pip install pillow\n",
    "!pip install qwen-agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1c8c85",
   "metadata": {},
   "source": [
    "## Import Libraries and Initialize Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90680a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path to import our modules\n",
    "sys.path.append(str(Path.cwd()))\n",
    "\n",
    "from see_think_act_agent import SeeThinkActAgent\n",
    "\n",
    "# Configure logging for notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "print(\"‚úì Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17d7985",
   "metadata": {},
   "source": [
    "## Test Ollama Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f066b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ollama_client import OllamaVisionClient\n",
    "\n",
    "# Test connection to Ollama\n",
    "client = OllamaVisionClient(model=\"qwen3-vl:235b-cloud\")\n",
    "\n",
    "print(\"Testing Ollama connection...\")\n",
    "if client.test_connection():\n",
    "    print(\"\\n‚úì Ollama is running and model is available!\")\n",
    "    print(\"‚úì Ready to start the agent\")\n",
    "else:\n",
    "    print(\"\\n‚úó Could not connect to Ollama or model not found\")\n",
    "    print(\"\\nPlease ensure:\")\n",
    "    print(\"1. Ollama is installed and running\")\n",
    "    print(\"2. Model is pulled: ollama run qwen3-vl:235b-cloud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44e4ba",
   "metadata": {},
   "source": [
    "## Initialize the See-Think-Act Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78921145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the agent\n",
    "agent = SeeThinkActAgent(\n",
    "    model=\"qwen3-vl:235b-cloud\",\n",
    "    max_iterations=30,  # Maximum number of actions before stopping\n",
    "    save_screenshots=True,  # Save screenshots for debugging\n",
    "    screenshot_dir=\"agent_screenshots\",\n",
    "    log_level=\"INFO\"\n",
    ")\n",
    "\n",
    "print(\"‚úì Agent initialized successfully!\")\n",
    "print(f\"  Model: qwen3-vl:235b-cloud\")\n",
    "print(f\"  Max iterations: 30\")\n",
    "print(f\"  Screenshots will be saved to: agent_screenshots/\")\n",
    "print(f\"  Screen size: {agent.action_executor.screen_width}x{agent.action_executor.screen_height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba569f",
   "metadata": {},
   "source": [
    "## Example 1: Simple Task - Open Notepad and Type Text\n",
    "\n",
    "This example demonstrates a simple task where the agent will:\n",
    "1. Find and click on the Start menu\n",
    "2. Search for Notepad\n",
    "3. Open Notepad\n",
    "4. Type some text\n",
    "\n",
    "**Note:** Make sure your desktop is visible and not covered by other windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae7be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define a simple task\n",
    "task1 = \"Open Notepad and type 'Hello from the AI Agent! This is a test of autonomous computer control.'\"\n",
    "\n",
    "print(f\"Task: {task1}\")\n",
    "print(\"\\nStarting agent...\")\n",
    "print(\"The agent will now take control and complete the task autonomously.\\n\")\n",
    "\n",
    "# Run the agent\n",
    "result = agent.run(task1)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TASK COMPLETED!\")\n",
    "print(\"=\" * 80)\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f2a4c7",
   "metadata": {},
   "source": [
    "## Example 2: Web Browsing Task\n",
    "\n",
    "This example demonstrates a more complex task involving web browsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea9ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a web browsing task\n",
    "task2 = \"Open Microsoft Edge browser and search for 'Ollama AI'\"\n",
    "\n",
    "print(f\"Task: {task2}\")\n",
    "print(\"\\nStarting agent...\\n\")\n",
    "\n",
    "# Run the agent\n",
    "result = agent.run(task2)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TASK COMPLETED!\")\n",
    "print(\"=\" * 80)\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8e8bec",
   "metadata": {},
   "source": [
    "## Example 3: Custom Task\n",
    "\n",
    "Run your own custom task! The agent will autonomously figure out how to complete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7087eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom task here\n",
    "custom_task = \"Open Calculator and calculate 123 + 456\"\n",
    "\n",
    "print(f\"Task: {custom_task}\")\n",
    "print(\"\\nStarting agent...\\n\")\n",
    "\n",
    "# Run the agent\n",
    "result = agent.run(custom_task)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TASK COMPLETED!\")\n",
    "print(\"=\" * 80)\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50f99f6",
   "metadata": {},
   "source": [
    "## View Saved Screenshots\n",
    "\n",
    "The agent saves screenshots at each iteration. You can view them to see what the agent saw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "# List all screenshots\n",
    "screenshot_dir = \"agent_screenshots\"\n",
    "if os.path.exists(screenshot_dir):\n",
    "    screenshots = sorted([f for f in os.listdir(screenshot_dir) if f.endswith('.png')])\n",
    "    \n",
    "    print(f\"Found {len(screenshots)} screenshots\\n\")\n",
    "    \n",
    "    # Display the first few screenshots\n",
    "    for i, screenshot_file in enumerate(screenshots[:5]):  # Show first 5\n",
    "        print(f\"\\n--- Screenshot {i+1}: {screenshot_file} ---\")\n",
    "        img = Image.open(os.path.join(screenshot_dir, screenshot_file))\n",
    "        # Resize for display\n",
    "        img.thumbnail((800, 600))\n",
    "        display(img)\n",
    "else:\n",
    "    print(f\"No screenshots found in {screenshot_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8388c89e",
   "metadata": {},
   "source": [
    "## How It Works\n",
    "\n",
    "The See-Think-Act Agent operates in a continuous loop:\n",
    "\n",
    "1. **SEE** üëÅÔ∏è\n",
    "   - Captures a screenshot of the current desktop state\n",
    "   - Uses the `mss` library for efficient screen capture on Windows\n",
    "\n",
    "2. **THINK** üß†\n",
    "   - Sends the screenshot to Qwen3-VL model via Ollama\n",
    "   - The model analyzes the image and decides the next action\n",
    "   - Uses function calling to structure the response\n",
    "\n",
    "3. **ACT** üéØ\n",
    "   - Executes the action decided by the model\n",
    "   - Uses `pyautogui` for mouse/keyboard control\n",
    "   - Actions include: click, type, scroll, key press, etc.\n",
    "\n",
    "4. **REPEAT** üîÑ\n",
    "   - Captures a new screenshot to see the result\n",
    "   - Continues until the task is marked as complete\n",
    "   - Maximum iterations prevent infinite loops\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Autonomous Operation**: The agent decides all actions independently\n",
    "- **Visual Grounding**: Uses computer vision to understand the UI\n",
    "- **Function Calling**: Structured actions via tool use\n",
    "- **Error Recovery**: Can adapt if actions don't work as expected\n",
    "- **Screenshot History**: Saves all screenshots for debugging\n",
    "- **Safe Operation**: Includes failsafe (move mouse to corner to stop)\n",
    "\n",
    "## Tips for Best Results\n",
    "\n",
    "1. **Clear Desktop**: Start with a clear, unobstructed desktop\n",
    "2. **Specific Tasks**: Give clear, specific instructions\n",
    "3. **Reasonable Scope**: Start with simple tasks and build up\n",
    "4. **Monitor Progress**: Watch the agent work (it's educational!)\n",
    "5. **Interrupt if Needed**: Press Ctrl+C or move mouse to top-left corner\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "- **Model not found**: Run `ollama pull qwen3-vl:235b-cloud`\n",
    "- **Ollama not running**: Start Ollama service\n",
    "- **Actions too fast**: Increase wait times in action_executor.py\n",
    "- **Mouse control issues**: Adjust screen size in agent initialization\n",
    "- **Permission errors**: Run with appropriate permissions for screen capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e286eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See-Think-Act Agent Demo for Windows 11\n",
    "This notebook demonstrates the autonomous AI Agent that can see, think, and act to perform tasks on Windows 11 using Ollama with Qwen3-VL.\n",
    "\n",
    "## Features\n",
    "- **See**: Captures screenshots of the desktop using efficient Windows APIs\n",
    "- **Think**: Analyzes screenshots with Qwen3-VL model via Ollama\n",
    "- **Act**: Executes mouse, keyboard, and system actions autonomously\n",
    "- **Loop**: Continues until task completion or max iterations reached\n",
    "\n",
    "## Prerequisites\n",
    "1. Ollama installed and running\n",
    "2. Qwen3-VL model pulled: `ollama run qwen3-vl:235b-cloud`\n",
    "3. Required Python packages installed (see requirements.txt)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
